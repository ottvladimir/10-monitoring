# Домашнее задание к занятию "10.06. Инцидент-менеджмент"

## Задание 1
## Постмортем  


|  |  |
|--|--|
| Краткое описание инцидента |Произошел инцидент, который привел к ухудшению обслуживания в течение 24 часов и 11 минут. Хотя некоторые части платформы не пострадали от этого инцидента, были затронуты несколько внутренних систем, что привело к тому, что платформа отображала устаревшую и противоречивую информацию.|
|Предшествующие события |В 22:52 UTC 21 октября были проведены плановые работы по техническому обслуживанию для замены вышедшего из строя оптического оборудования 100G|
|Причина инцидента | Работы привели к потере связи между нашим сетевым узлом на Восточном побережье США и основным центром обработки данных на Восточном побережье США. Связь между этими точками была восстановлена за 43 секунды.|
|Воздействие | Это короткое отключение вызвало цепочку событий, которые привели к 24 часам и 11 минутам ухудшения качества обслуживания. |
|Обнаружение | 23:02 UTC инженеры из нашей команды первой линии определили, что топологии для многочисленных кластеров баз данных находятся в состоянии unexpected. Запрос к API Orchestrator показал что репликации базы данных, включали только серверы из ЦОД на Западном побережье США|
|Реакция     | Реакция заключалась в том, чтобы уделять приоритетное внимание целостности данных, а не удобству использования сайта и времени на восстановление. В качестве предосторожности были предприняты шаги для обеспечения целостности ваших данных, включая приостановку работы событий (hooks) и других внутренних систем обработки.|
|Восстановление | План восстановления состоял в том, чтобы восстановить данные из резервных копий, синхронизировать реплики на обоих сайтах, вернуться к стабильной топологии обслуживания, а затем возобновить обработку заданий в очереди. |
|Таймлайн |22:54 UTC Внутренние системы мониторинга начали генерировать предупреждения, указывающие на многочисленные сбои.
||23:07 UTC К этому моменту дежурная смена решила вручную заблокировать внутренний инструментарий развертывания, чтобы предотвратить внесение дополнительных изменений.
||23:13 UTC Стало понятно что проблема затронула несколько кластеров баз данных. Были вызваны дополнительные инженеры из команды разработчиков баз данных GitHub.
||00:41 UTC К этому времени был начат процесс резервного копирования для всех затронутых кластеров MySQL, и инженеры отслеживали прогресс.
||11:12 UTC Все праймериз базы данных снова созданы на Восточном побережье США.
||16:24 UTC Реплики были синхронизированы, мы выполнили переход на исходную топологию, решив проблемы с задержкой / доступностью.|
||23:03 UTC  Все незавершенные сборки веб-приложений и страниц были обработаны, и была подтверждена целостность и правильная работа всех систем.|
|Последующие действия | Во время нашего восстановления мы записали двоичные журналы MySQL, содержащие записи, которые не были реплицированы на наш сайт на Западном побережье из каждого затронутого кластера.|
|||


